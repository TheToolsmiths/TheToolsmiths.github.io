---
title: 'Tools Design Roundtable Day 3: User Research'
layout: codex_notes_page
author: Igor de Sousa
author_url: https://www.linkedin.com/in/igorrafaeldesousa/
permalink: /codex/gdc/roundtable/tools_design/2024/day-3
nav_tag: gdc
---
{% include JB/setup %}

<br>

# @ GDC 2024


## Good things

- Tool for selecting/filtering dependencies for plugins
- In depth telemetry: proactive reaching out to users
- Feedback on user sentiment about the tool
- Having telemetry is great

## Bad things

- Outdated tool: some users don't want to use the new tool
- Black market of tools and Python scripts
- Hard to get feedback on the tools
    - Vocal minority?
    - Users who don't even care to report?
- Users biased against in-house tools

## General resources

- https://thetoolsmiths.org
- https://rystorm.com
- David Lightbown's book: https://www.amazon.com/Designing-User-Experience-Development-Tools/dp/1138427632

## Tools for research

- General advice: paying per user gets expensive and doesn't scale well
- Mind map manager
    - Doesn't handle timestamps well
- Parsec
- Specialized services:
    - https://usertesting.com
    - https://devetail.com
    - https://heymarvin.com
    - Plain forms (Office, Google Forms)
    - Morae
    - Teams + Miro recording
- Miro AI features

## Metrics

- Net Promoter Score (NPS): easy but not suited by internal tools
- CSat: customer satisfaction
- Technology Acceptance Model (TAM):
    - Theres also a simplified version with 2 questions: was this useful? was this usable?
- Busting open doors: go ask
- CASTLE, derived from the HART model: focused on the productivity tools and content creation
- In house models
- User Experience Questionnaire
- "Are we making enough to make the game ship?"

## Making user accept changes

- Lighthouse teams
- New features only on the new tool
- Ensure your tool is actually good
- Get different people involved, get people excited
- Establish rapport with the user: one team
- 30 days challenge
    - follow up with user later
    - events
- Multi-disciplinar cell/strike team working on the tool
- Dialogue to select the tool version when launching and track the choiced
    - Time bomb that will launch the new version

## Collation of research

- Links to metrics and requests on the header of UI
- Separate Jira instance for feedback
- Ensure higher-ups understand the need for UX researches to make evidence based decisions


## Culture of design

- Steve Krug: don't make me 
- Watch people use the tool
- Evaluating the tool, not the user
- Multiple short sessions, develop relationship
- Ask to be taught how to use the tool
- Pre-session Spiel
- Having people watch remotely
- Be neutral
- Normaliza screen-sharing
- OBS in time-lapse mode
- Ask the producer to schedule time for testing
